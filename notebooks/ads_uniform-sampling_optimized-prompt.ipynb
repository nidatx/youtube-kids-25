{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10328861,"sourceType":"datasetVersion","datasetId":6395471},{"sourceId":10349036,"sourceType":"datasetVersion","datasetId":6296913},{"sourceId":10358109,"sourceType":"datasetVersion","datasetId":5987034},{"sourceId":10391050,"sourceType":"datasetVersion","datasetId":5684885},{"sourceId":10550838,"sourceType":"datasetVersion","datasetId":6411015}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports","metadata":{"id":"exmY-abTefFW"}},{"cell_type":"code","source":"!pip install ffmpeg-python\n!pip install av\n!pip install -q -U google-generativeai\n!pip install --upgrade pip\n!pip install --upgrade transformers datasets[audio] accelerate","metadata":{"id":"Bi3c0wLhh-Rf","outputId":"44c463e5-7c4c-45cf-daca-75620249739c","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:00:54.527753Z","iopub.execute_input":"2025-01-06T07:00:54.528151Z","iopub.status.idle":"2025-01-06T07:02:26.402581Z","shell.execute_reply.started":"2025-01-06T07:00:54.528116Z","shell.execute_reply":"2025-01-06T07:02:26.401080Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport torch\nimport random\nimport ffmpeg\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom glob import glob\nimport soundfile as sf\nfrom json import loads,dumps\n#from pydub import AudioSegment\nimport matplotlib.pyplot as plt\nfrom scipy.signal import resample\nimport typing_extensions as typing\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:02:26.405115Z","iopub.execute_input":"2025-01-06T07:02:26.405546Z","iopub.status.idle":"2025-01-06T07:02:26.412999Z","shell.execute_reply.started":"2025-01-06T07:02:26.405508Z","shell.execute_reply":"2025-01-06T07:02:26.411680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting all required ids \n\nlabels_df = pd.read_csv('/kaggle/input/youtube-data/all_unique_codes3.csv') \n\ntranscriptions_df = pd.read_csv('/kaggle/input/youtube-data/Translated-transcriptions.csv')\ndf = pd.merge(labels_df, transcriptions_df, left_on='Video link', right_on='Video Id')\n\ndf.rename(columns={'Primary Tag': 'Primary Label'}, inplace=True)\ndf ","metadata":{"id":"1ksUpR0ibKve","outputId":"6880ee21-f703-4761-dfcd-842e1f8b61d9","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:54:47.985381Z","iopub.execute_input":"2025-01-06T06:54:47.985776Z","iopub.status.idle":"2025-01-06T06:54:48.176841Z","shell.execute_reply.started":"2025-01-06T06:54:47.985739Z","shell.execute_reply":"2025-01-06T06:54:48.175606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filtering out available ads and those that are either inappropriate or child directed\n\ndf = df[(df['Primary Label'] == 'inappropriate') | (df['Primary Label'] == 'child directed') | (df['Primary Label'] == 'irrelevant')]","metadata":{"id":"G9PECX_Mra4j","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:54:49.020159Z","iopub.execute_input":"2025-01-06T06:54:49.020579Z","iopub.status.idle":"2025-01-06T06:54:49.028907Z","shell.execute_reply.started":"2025-01-06T06:54:49.020545Z","shell.execute_reply":"2025-01-06T06:54:49.027723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting video ids and primary labels\n\nvideo_ids = list(df['Video link'])\nprimary_labels = list(df['Primary Label'])\nall_transcriptions = list(df['Transcription'])","metadata":{"id":"oR7rNEX3rl2I","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:54:51.375888Z","iopub.execute_input":"2025-01-06T06:54:51.376394Z","iopub.status.idle":"2025-01-06T06:54:51.383652Z","shell.execute_reply.started":"2025-01-06T06:54:51.376355Z","shell.execute_reply":"2025-01-06T06:54:51.382362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(video_ids)","metadata":{"id":"J3gA6uDHSKoG","outputId":"7cf01806-916f-48f9-e17e-9e267e208d36","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T06:54:52.772431Z","iopub.execute_input":"2025-01-06T06:54:52.772857Z","iopub.status.idle":"2025-01-06T06:54:52.780258Z","shell.execute_reply.started":"2025-01-06T06:54:52.772823Z","shell.execute_reply":"2025-01-06T06:54:52.778964Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting data from transcripts\n\ntranscriptions = []\nlengths = []\n\nfor (i, id_) in enumerate(video_ids):\n    transcriptions.append(all_transcriptions[i].split(\"chunks\")[0])\n    lengths.append(len(all_transcriptions[i].split(\"chunks\")[0]))\n","metadata":{"id":"_7p-efT9sNMf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"available_ids = os.listdir('/kaggle/input/youtube-data/Ads/Ads') \nlen(available_ids) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Extracting Images ","metadata":{}},{"cell_type":"code","source":"def extract_single_image(video_path, num_frames=6):\n    cap = cv2.VideoCapture(video_path)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n\n    # Calculate the interval at which to sample frames\n    interval = max(1, total_frames // num_frames)\n    frames = []\n\n    # Extract frames at regular intervals\n    for i in range(num_frames):\n        frame_no = i * interval\n        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)\n        ret, frame = cap.read()\n        if ret:\n            frames.append(frame)\n\n    cap.release()\n\n    # Ensure the correct number of frames were extracted\n    if len(frames) < num_frames:\n        raise ValueError(\"Not enough frames extracted from the video.\")\n\n    # Concatenate all frames into a single image\n    try:\n        concatenated_rows = []\n        for i in range(0, num_frames, 2):\n            row = np.concatenate(frames[i:i+2], axis=1)\n            concatenated_rows.append(row)\n        concatenated_image = np.concatenate(concatenated_rows, axis=0)\n    except Exception as e:\n        raise ValueError(f\"Error during frame concatenation: {e}\")\n\n    # Resize the final image\n    final_image = Image.fromarray(concatenated_image).resize((1000, 1000))\n\n    return np.array(final_image)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"key_ = '' # add key here ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai \nos.environ[\"API_KEY\"] = maham\ngenai.configure(api_key=os.environ[\"API_KEY\"]) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available()) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define Model ","metadata":{}},{"cell_type":"code","source":"model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=\"You are an expert content moderator.\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LLM_Output(typing.TypedDict):\n    label: str\n    language: list[str]\n    response: str","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Prompt ","metadata":{}},{"cell_type":"code","source":"prompt = \"\"\" A video can be considered inappropriate for children if it contains physical violence (cartoonish, realistic, inclusion of gore),\n  interpersonal violence (such as bullying, pranks, meanness, humor at expense of others, belittling ,controlling, talking down to, or manipulating others),\n  self-harm or suicide,\n  elements of scariness (horror, scary themes, creepy or suspenseful themes, loud and violent content, zombies, skeletons, scary masks, scary clowns, blood, fire in dangerous settings,\n  mentally distressing scenes (car crashes, medical procedures etc),\n  extreme stunts (depictions of life endangering or high-risk physical activities/challenges),\n  sexual content (innuendos, overt sexual behavior, nudity, sexual themes, sexual suggestiveness),\n  discrimination (based on race/ethnicity/gender/ability),\n  offensive language (from mild words such as \"idiot\" and \"stupid\" to severe swearing, hate speech or signs),\n  drinking, drugs, smoking, gambling, crude humour,\n  inappropriate clothing (with significant skin exposure),\n  death,\n  intimacy (sensual physical contact, marriage, romance, dating and relationships, apparent romantic conduct between subjects/actors).\n  romantic songs and music.\n\n  You have been given a image grid (3 x 2) representing a video and it's audio transcription.\n  Consider that you are a Parent. Based on both the visual content and audio transcription, is the video ad provided inappropriate for children under 9 based on this definition?\n  \n  If it is, label it as \"inappropriate\".\n  If it is not, label it as \"appropriate\".\n\n  Justify your conclusion.\n\n  Also, mention what language is being spoken if there is any.\n\n  Make the outputs in JSON format.\n\n  \"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Define function","metadata":{"id":"w8esg7q8hSTW"}},{"cell_type":"code","source":"len(video_ids)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = []\npredicted_labels = []\nlanguages = []\nresponses = []\nground_truths = []\nremaining = []\n\nimg_dir = '/kaggle/working/Images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)\n    \nfor i in range(len(video_ids)): \n    \n    if video_ids[i] in available_ids:\n\n        try:\n            contents_of_ad = os.listdir('/kaggle/input/youtube-data/Ads/Ads/' + video_ids[i]) \n            contents_of_ad.remove('audio.mp3') \n            video_path = '/kaggle/input/youtube-data/Ads/Ads/' + video_ids[i] + '/' + contents_of_ad[0] \n\n            #print(video_path)\n\n            # Extract a grid image representative of entire video\n            grid = extract_single_image(video_path)\n\n            # Convert NumPy array to PIL image\n            image = Image.fromarray(grid)\n\n            # Save the image to a file\n            image_name = video_ids[i] + \".png\"\n            image_path = os.path.join(img_dir, image_name)\n            image.save(image_path)\n            \n            # Display the image\n            plt.imshow(image)\n            plt.axis('off')\n            plt.tight_layout()\n            plt.show()\n\n            # Wrap image upload in try-except\n            try:\n                image_file = genai.upload_file(path = image_path, resumable=False)\n            except Exception as e:\n                print(f\"Error uploading image: {e}\")\n                remaining.append(video_ids[i])\n                continue\n\n            # Upload audio\n            audio = transcriptions[i] \n\n            # Check if image has uploaded\n            try:\n                while image_file.state.name == \"PROCESSING\":\n                    print('.', end='')\n                    time.sleep(10)\n                    image_file = genai.get_file(image_file.name)\n\n                if image_file.state.name == \"FAILED\":\n                    raise ValueError(image_file.state.name)\n            except Exception as e:\n                print(f\"Error during image processing: {e}\")\n                remaining.append(video_ids[i])\n                continue\n\n            # Make inference\n            try:\n                response = model.generate_content([audio, image_file, prompt],\n                                                  generation_config=genai.GenerationConfig(\n                                                      response_mime_type=\"application/json\",\n                                                      response_schema=LLM_Output),\n                                                  safety_settings={\n                                                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n                                                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n                                                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n                                                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n                                                  })\n            except Exception as e:\n                print(f\"Error making inference: {e}\")\n                remaining.append(video_ids[i])\n                continue\n\n            # Wrap response.text access in try-except\n            try:\n                print(\"Completed for video number:\", i, \"\\t\", video_ids[i])\n\n                dictionary = loads(response.text)\n                print(dictionary)\n\n                ids.append(video_ids[i])\n                predicted_labels.append(dictionary['label'])\n                languages.append(dictionary['language'])\n                responses.append(dictionary['response'])\n                ground_truths.append(primary_labels[i]) \n                \n            except Exception as e:\n                print(f\"Error processing response.text: {e}\")\n                remaining.append(video_ids[i])\n                continue\n\n        except Exception as e:\n            print(f\"Unexpected error: {e}\")\n            remaining.append(video_ids[i])\n            continue\n\n        # Wait a bit to avoid exceeding rate limits\n        time.sleep(20)\n\n# At the end, print remaining videos\nprint(\"Remaining videos with errors:\", remaining)","metadata":{"id":"cSoT7-9DDknR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(responses)): \n    print('True Label: ', ground_truths[i], '\\tPrediction: ', predicted_labels[i]) ","metadata":{"id":"aqDlWLZcZJHL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_labels ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = pd.DataFrame({\n    'Video Id': ids,\n    'Primary Label': ground_truths,\n    'Predicted Label': predicted_labels,\n    'Response': responses, \n    'Languages': languages \n})\n\nnew_df.head() ","metadata":{"id":"6JsiW7gbvxRA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_dir = '/kaggle/working/results'\nif not os.path.exists(results_dir):\n    os.makedirs(results_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df.to_csv('/kaggle/working/results/uniformly-sampled-frames_+_translated-aduios.csv', index=False) ","metadata":{"id":"Tv1_5sfJwRfu","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Changing to binary lists \n\npredictions = [1 if pred == 'inappropriate' else 0 for pred in predicted_labels] \nground_truths = [1 if label == 'inappropriate' else 0 for label in ground_truths] ","metadata":{"id":"4hsLj8P8Mg-e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtaining classification report \nfrom sklearn.metrics import classification_report \n\nreport = classification_report(ground_truths, predictions) \nprint(report) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(ground_truths, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Appropriate', 'Inapproriate'], yticklabels=['Appropriate', 'Inapproriate'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}