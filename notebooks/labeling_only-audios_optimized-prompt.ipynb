{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10328861,"sourceType":"datasetVersion","datasetId":6395471},{"sourceId":10349036,"sourceType":"datasetVersion","datasetId":6296913},{"sourceId":10358109,"sourceType":"datasetVersion","datasetId":5987034},{"sourceId":10549716,"sourceType":"datasetVersion","datasetId":6179624},{"sourceId":10550838,"sourceType":"datasetVersion","datasetId":6411015}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{"id":"exmY-abTefFW"}},{"cell_type":"code","source":"!pip install ffmpeg-python\n!pip install av\n!pip install -q -U google-generativeai\n!pip install --upgrade pip\n!pip install --upgrade transformers datasets[audio] accelerate\n!pip install scenedetect","metadata":{"id":"Bi3c0wLhh-Rf","outputId":"44c463e5-7c4c-45cf-daca-75620249739c","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:22:40.332676Z","iopub.execute_input":"2025-01-22T14:22:40.333035Z","iopub.status.idle":"2025-01-22T14:23:36.686411Z","shell.execute_reply.started":"2025-01-22T14:22:40.333008Z","shell.execute_reply":"2025-01-22T14:23:36.685250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport cv2\nimport time\nimport torch\nimport random\nimport ffmpeg\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom glob import glob\nimport soundfile as sf\nfrom json import loads,dumps\n#from pydub import AudioSegment\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom scipy.signal import resample\nimport typing_extensions as typing\nfrom google.generativeai.types import HarmCategory, HarmBlockThreshold\nfrom scenedetect import open_video, VideoStreamCv2, SceneManager\nfrom scenedetect.detectors import ContentDetector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:36.687747Z","iopub.execute_input":"2025-01-22T14:23:36.688023Z","iopub.status.idle":"2025-01-22T14:23:44.548030Z","shell.execute_reply.started":"2025-01-22T14:23:36.687998Z","shell.execute_reply":"2025-01-22T14:23:44.547073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"limit = 5000 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.549722Z","iopub.execute_input":"2025-01-22T14:23:44.550261Z","iopub.status.idle":"2025-01-22T14:23:44.554085Z","shell.execute_reply.started":"2025-01-22T14:23:44.550231Z","shell.execute_reply":"2025-01-22T14:23:44.553175Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"# Setting up video directories \n\ntrue1dir = '/kaggle/input/video-classification-data/Videos/Videos/videos-true' \ntrue2dir = '/kaggle/input/video-classification-data/Videos/Videos/videos-true-2' \nkids_dir = '/kaggle/input/video-classification-data/Made-For-Kids/Made-For-Kids'\n\nfalse1dir = '/kaggle/input/video-classification-data/Videos/Videos/videos-false' \nfalse2dir = '/kaggle/input/video-classification-data/Videos/Videos/videos-false-2' \nnon_kids_dir = '/kaggle/input/video-classification-data/Non Made For Kids/Non Made For Kids'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.555500Z","iopub.execute_input":"2025-01-22T14:23:44.555865Z","iopub.status.idle":"2025-01-22T14:23:44.581758Z","shell.execute_reply.started":"2025-01-22T14:23:44.555831Z","shell.execute_reply":"2025-01-22T14:23:44.580417Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Functions to extract corresponding transcriptions and ground truths \n\ndef get_transcriptions_and_paths(vids_dir, ground_truths, transcriptions_path): \n\n    ids = os.listdir(vids_dir) \n\n    labels_df = pd.DataFrame({ \n        'IDs': ids, \n        'Labels': [ground_truths] * len(ids) \n    }) \n    \n    transcriptions_df = pd.read_csv(transcriptions_path) \n    \n    # Merging dataframes \n    df = pd.merge(labels_df, transcriptions_df, left_on='IDs', right_on='Video Id') \n\n    # Extracting transcriptions \n    ids = list(df['IDs']) \n    paths = [vids_dir + '/' + id for id in ids] \n    all_transcriptions = list(df['Transcription']) \n\n    # Extracting data from transcripts \n    transcriptions_temp = [] \n    lengths = [] \n    for (i, id_) in enumerate(ids): \n        transcriptions_temp.append(all_transcriptions[i].split(\"chunks\")[0]) \n        lengths.append(len(all_transcriptions[i].split(\"chunks\")[0])) \n\n    # setting limit on transcription length \n    transcriptions = [x[:limit] + '...' if len(x) > limit else x for x in transcriptions_temp] \n\n    return paths, transcriptions, [ground_truths] * len(ids) ","metadata":{"id":"1ksUpR0ibKve","outputId":"6880ee21-f703-4761-dfcd-842e1f8b61d9","trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.582822Z","iopub.execute_input":"2025-01-22T14:23:44.583130Z","iopub.status.idle":"2025-01-22T14:23:44.594169Z","shell.execute_reply.started":"2025-01-22T14:23:44.583104Z","shell.execute_reply":"2025-01-22T14:23:44.593178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loading paths, transcriptions, and labels \n\ntrans_dir = '/kaggle/input/child-safety-base-experiment-results/Videos - Native Transcriptions/Videos - Native Transcriptions/native_language_transcriptions_' # replace with translated transcriptions directory for english transcriptions only \n\ntrue1_paths, true1_transcriptions, true1_labels = get_transcriptions_and_paths(true1dir, 'Child Directed', trans_dir + 'true1.csv') \ntrue2_paths, true2_transcriptions, true2_labels = get_transcriptions_and_paths(true2dir, 'Child Directed', trans_dir + 'true2.csv') \nkids_paths, kids_transcriptions, kids_labels = get_transcriptions_and_paths(kids_dir, 'Child Directed', trans_dir + 'made-for-kids.csv') \n\nfalse1_paths, false1_transcriptions, false1_labels = get_transcriptions_and_paths(false1dir, 'Not Child Directed', trans_dir + 'false1.csv') \nfalse2_paths, false2_transcriptions, false2_labels = get_transcriptions_and_paths(false2dir, 'Not Child Directed', trans_dir + 'false2.csv') \nnon_kids_paths, non_kids_transcriptions, non_kids_labels = get_transcriptions_and_paths(non_kids_dir, 'Not Child Directed', trans_dir + 'non-made-for-kids.csv') ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.595061Z","iopub.execute_input":"2025-01-22T14:23:44.595420Z","iopub.status.idle":"2025-01-22T14:23:44.732266Z","shell.execute_reply.started":"2025-01-22T14:23:44.595386Z","shell.execute_reply":"2025-01-22T14:23:44.731225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final combined list of paths and ground labels \n\npaths = [] \ntranscriptions = [] \nprimary_labels = [] \n\npaths.extend(false1_paths) \npaths.extend(true1_paths) \npaths.extend(false2_paths) \npaths.extend(true2_paths) \npaths.extend(non_kids_paths)\npaths.extend(kids_paths) \n\nprimary_labels.extend(false1_labels) \nprimary_labels.extend(true1_labels) \nprimary_labels.extend(false2_labels) \nprimary_labels.extend(true2_labels) \nprimary_labels.extend(non_kids_labels) \nprimary_labels.extend(kids_labels) \n\ntranscriptions.extend(false1_transcriptions) \ntranscriptions.extend(true1_transcriptions) \ntranscriptions.extend(false2_transcriptions) \ntranscriptions.extend(true2_transcriptions) \ntranscriptions.extend(non_kids_transcriptions) \ntranscriptions.extend(kids_transcriptions) \n\nvideo_ids = [path.split('/')[-1] for path in paths]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.741591Z","iopub.execute_input":"2025-01-22T14:23:44.741878Z","iopub.status.idle":"2025-01-22T14:23:44.758746Z","shell.execute_reply.started":"2025-01-22T14:23:44.741855Z","shell.execute_reply":"2025-01-22T14:23:44.757662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(paths), len(primary_labels), len(transcriptions), len(video_ids)) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.759873Z","iopub.execute_input":"2025-01-22T14:23:44.760203Z","iopub.status.idle":"2025-01-22T14:23:44.783044Z","shell.execute_reply.started":"2025-01-22T14:23:44.760173Z","shell.execute_reply":"2025-01-22T14:23:44.781967Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Defining Model** ","metadata":{}},{"cell_type":"code","source":"key_ = '' # add key here ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T14:23:44.784079Z","iopub.execute_input":"2025-01-22T14:23:44.784374Z","iopub.status.idle":"2025-01-22T14:23:44.799899Z","shell.execute_reply.started":"2025-01-22T14:23:44.784350Z","shell.execute_reply":"2025-01-22T14:23:44.798775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import google.generativeai as genai \nos.environ[\"API_KEY\"] = key_ \ngenai.configure(api_key=os.environ[\"API_KEY\"]) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=\"You are an expert content moderator.\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LLM_Output(typing.TypedDict):\n    label: str\n    language: list[str]\n    response: str","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Prompt** ","metadata":{}},{"cell_type":"code","source":"# Create the prompt.\nprompt = \"\"\"\n    A piece of content is child-directed if it meets any of these criteria:\n\n    Designed for Children:\n    The content is explicitly created with children as the intended audience, such as:\n      - Educational videos for kids.\n      - Child-friendly video games with cartoonish graphics and non-violent gameplay and story-telling\n      - Animated movies/clips suitable for family viewing\n      - Simple crafts, activities, or demonstrations aimed at children.\n\n    Child-Appealing Elements:\n    The content includes features commonly enjoyed by children, such as:\n    - Colorful, cartoonish, or animated visuals (e.g., animals, anthropomorphic characters, fantasy creatures).\n    - Light-hearted portrayals of themes like mischief or conflict, but without mature visuals, strong language, or adult humor.\n    - Whimsical, or playful themes.\n    - Non-violent and simplified gameplay or narratives.\n    - Content with rhythmic elements (e.g., chants, exclamations, or songs appealing to young viewers).\n\n    Important Considerations:\n    - Content can be child-directed even if it also appeals to older audiences.\n    - Gaming content is child-directed if it features family-friendly gameplay and cartoonish visuals.\n    - Movie/TV clips are child-directed if rated G/PG.\n    - Presence of mild peril or conflict is acceptable if presented appropriately.\n\n    Exclusions:\n    - Do not label content as \"Child Directed\" if it features significant:\n      - Dark, mature, or violent themes.\n      - Romantic subplots or adult humor.\n      - Complex dialogue or advanced vocabulary inappropriate for children.\n      - Songs that are not nursery rhymes or explicitly created for children.\n    - Recipe, DIY, or instructional videos unless simplified for children (e.g., \"Cooking for Kids\").\n\n    Instructions:\n    Labeling:\n    If the video meets the child-directed criteria label it as \"Child Directed\".\n    If it does not meet these criteria label it as \"Not Child Directed\".\n\n    Indicate the spoken language if any.\n    Provide a brief justification explaining why the video is considered child-directed or not.\n\n    Format the output in JSON.\n  \"\"\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Running Model on Dataset** ","metadata":{"id":"w8esg7q8hSTW"}},{"cell_type":"code","source":"ids = []\npredicted_labels = []\nlanguages = []\nresponses = []\nground_truths = []\nremaining = []\n\nimg_dir = '/kaggle/working/Images'\nif not os.path.exists(img_dir):\n    os.makedirs(img_dir)\n\nfor i in range(len(paths)): \n    try:\n        contents_of_ad = os.listdir(paths[i]) \n        contents_of_ad.remove('audio.mp3') \n        video_path = paths[i] + '/' + contents_of_ad[0] \n        audio_path = paths[i] + '/audio.mp3' \n\n        # Make inference with audio and image URIs\n        audio = transcriptions[i]\n        try: \n            inputs_ = [audio] \n            inputs_.extend([prompt]) \n            response = model.generate_content(inputs_,\n                                              generation_config=genai.GenerationConfig(\n                                                  response_mime_type=\"application/json\",\n                                                  response_schema=LLM_Output, \n                                                  temperature=0.0), \n                                              safety_settings={\n                                                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n                                                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n                                                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n                                                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE\n                                              })\n        except Exception as e:\n            print(f\"Error making inference: {e}\")\n            remaining.append(video_ids[i])\n            continue\n\n        # Wrap response.text access in try-except\n        try:\n            print(\"\\nCompleted for video number:\", i, ' ', video_ids[i])\n\n            dictionary = loads(response.text)\n            print('True Label:', primary_labels[i], 'Response:', dictionary)\n\n            ids.append(video_ids[i])\n            predicted_labels.append(dictionary['label'])\n            languages.append(dictionary['language'])\n            responses.append(dictionary['response'])\n            ground_truths.append(primary_labels[i]) \n            \n        except Exception as e:\n            print(f\"Error processing response.text: {e}\")\n            remaining.append(video_ids[i])\n            continue\n\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        remaining.append(video_ids[i])\n        continue\n\n    time.sleep(20)","metadata":{"id":"cSoT7-9DDknR","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(ids)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# At the end, print remaining videos \n\nprint(\"Remaining videos with errors:\", remaining) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i in range(len(responses)): \n    print('True Label: ', ground_truths[i], '\\tPrediction: ', predicted_labels[i]) ","metadata":{"id":"aqDlWLZcZJHL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df = pd.DataFrame({\n    'Video Id': ids,\n    'Primary Label': ground_truths,\n    'Predicted Label': predicted_labels,\n    'Response': responses, \n    'Languages': languages \n})\n\nnew_df.head() ","metadata":{"id":"6JsiW7gbvxRA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_dir = '/kaggle/working/results'\nif not os.path.exists(results_dir):\n    os.makedirs(results_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_df.to_csv('/kaggle/working/results/audio-transcriptions-only.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Changing to binary lists \n\npredictions = [1 if pred == 'Not Child Directed' else 0 for pred in predicted_labels] \nground_truths = [1 if label == 'Not Child Directed' else 0 for label in ground_truths] ","metadata":{"id":"4hsLj8P8Mg-e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Obtaining classification report \nfrom sklearn.metrics import classification_report \n\nreport = classification_report(ground_truths, predictions) \nprint(report) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(ground_truths, predictions)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Not Child Directed', 'Child Directed'], yticklabels=['Not Child Directed', 'Child Directed'])\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}